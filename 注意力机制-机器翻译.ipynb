{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.ticker as ticker\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "import unicodedata\n",
    "import re\n",
    "import numpy as np\n",
    "import os\n",
    "import io\n",
    "import time"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 准备数据集"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "我们将使用 http://www.manythings.org/anki/ 提供的一个语言数据集。这个数据集包含如下格式的语言翻译对：  \n",
    "May I borrow this book? ¿Puedo tomar prestado este libro?\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "下载完毕数据集之后，我们需要做如下步骤：\n",
    "1. 给每一个句子添加一个开始与结束标记（token）\n",
    "2. 删除特殊字符以清理句子\n",
    "3. 创建一个单词索引与一个反向单词索引（word2idx，idx2word）\n",
    "4. 将每一个句子填充到最大长度（padding）"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 加载文件路径\n",
    "path_to_file='语料库/spa-eng/spa.txt'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 将unicode转为ascii\n",
    "def unicode_to_ascii(s):\n",
    "    return ''.join(c for c in unicodedata.normalize('NFD',s) if unicodedata.category(c)!=\"Mn\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def preprocess_sentence(w):\n",
    "    w = unicode_to_ascii(w.lower().strip())\n",
    "\n",
    "    # 在单词与跟在其后的标点符号之间插入一个空格\n",
    "    # 例如： \"he is a boy.\" => \"he is a boy .\"\n",
    "    # 参考：https://stackoverflow.com/questions/3645931/python-padding-punctuation-with-white-spaces-keeping-punctuation\n",
    "    w = re.sub(r\"([?.!,¿])\", r\" \\1 \", w)\n",
    "    w = re.sub(r'[\" \"]+', \" \", w)\n",
    "\n",
    "    # 除了 (a-z, A-Z, \".\", \"?\", \"!\", \",\")，将所有字符替换为空格\n",
    "    w = re.sub(r\"[^a-zA-Z?.!,¿]+\", \" \", w)\n",
    "\n",
    "    w = w.rstrip().strip()\n",
    "\n",
    "    # 给句子加上开始和结束标记\n",
    "    # 以便模型知道何时开始和结束预测\n",
    "    w = '<start> ' + w + ' <end>'\n",
    "    return w"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<start> i played basketball yesterday . <end>\n",
      "<start> ayer jugue al baloncesto . <end>\n"
     ]
    }
   ],
   "source": [
    "en_sentences=u'I played basketball yesterday.'\n",
    "sp_sentences=u'Ayer jugué al baloncesto.'\n",
    "print(preprocess_sentence(en_sentences))\n",
    "print(preprocess_sentence(sp_sentences))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 去除重音符号,如jugué 的 é 变为jugue\n",
    "# 清理句子\n",
    "# 返回单词对【English，Spanish，_(无用的信息）】\n",
    "def create_dataset(path,num_examples):\n",
    "    lines=io.open(path,encoding='UTF-8').read().strip().split('\\n')\n",
    "    word_pairs=[[preprocess_sentence(w) for w in l.split('\\t')] for l in lines[:min(num_examples,len(lines)-1) if num_examples else None]]\n",
    "    return zip(*word_pairs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<zip at 0x148640548>"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x=[1,2,3]\n",
    "y=[4,5,6]\n",
    "z=[7,8,9]\n",
    "\n",
    "w= zip(x,y,z)#[(1, 4, 7), (2, 5, 8), (3, 6, 9)]\n",
    "\n",
    "# zip() in conjunction with the * operator can be used to unzip a list:\n",
    "zip(*w) #[(1, 2, 3), (4, 5, 6), (7, 8, 9)]\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<start> it may be impossible to get a completely error free corpus due to the nature of this kind of collaborative effort . however , if we encourage members to contribute sentences in their own languages rather than experiment in languages they are learning , we might be able to minimize errors . <end>\n",
      "<start> puede que sea imposible obtener un corpus completamente libre de errores debido a la naturaleza de este tipo de esfuerzo de colaboracion . sin embargo , si animamos a los miembros a contribuir frases en sus propios idiomas en lugar de experimentar con los idiomas que estan aprendiendo , podriamos ser capaces de minimizar los errores . <end>\n"
     ]
    }
   ],
   "source": [
    "# create_dataset将list中的元素拆分为三份返回\n",
    "# en是第一个英文数据，sp是第二个西班牙文数据，第三个数据是后面不用管的\n",
    "en, sp,_ = create_dataset(path_to_file, None)\n",
    "print(en[-1])\n",
    "print(sp[-1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def max_length(tensor):\n",
    "    return max(len(t) for t in tensor)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# tf.keras.preprocessing.text.Tokenizer:\n",
    "# 此类允许通过将每个文本转换成整数序列（每个整数是字典中标记的索引）或转换成矢量（其中每个标记的系数可以是二进制的）的矢量化语料库，基于单词数 ，基于tf-idf ...\n",
    "\n",
    "# filters: a string where each element is a character that will be\n",
    "#          filtered from the texts. The default is all punctuation, plus\n",
    "#          tabs and line breaks, minus the `'` character.\n",
    "def tokenize(lang):\n",
    "    lang_tokenizer=tf.keras.preprocessing.text.Tokenizer(filters='')\n",
    "#     fit_on_texts:\n",
    "#     根据文本列表更新内部词汇。 在文本包含列表的情况下，我们假定列表的每个条目都是一个标记。 在使用texts_to_sequences或texts_to_matrix之前是必需的。\n",
    "    lang_tokenizer.fit_on_texts(lang)\n",
    "    # text_to_sequences:\n",
    "    # Transforms each text in texts to a sequence of integers.\n",
    "    # 只考虑前num_words-1词频的词，只考虑分词器已知的词\n",
    "\n",
    "    tensor=lang_tokenizer.texts_to_sequences(lang)\n",
    "    tensor=tf.keras.preprocessing.sequence.pad_sequences(tensor,padding='post')\n",
    "    return tensor,lang_tokenizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_dataset(path,num_examples=None):\n",
    "    # create_dataset 返回单词对【English，Spanish，_(无用的信息）】\n",
    "    target_lang,input_lang,_=create_dataset(path,num_examples)\n",
    "    input_tensor,input_lang_tokenizer=tokenize(input_lang)\n",
    "    target_tensor,target_lang_tokenizer=tokenize(target_lang)\n",
    "    return input_tensor,input_lang_tokenizer,target_tensor,target_lang_tokenizer"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 选择训练集大小"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 注意，训练集一共有123335条语句，并且训练集后面的语句更长\n",
    "# 所以训练集较小，对于较短的语句效果较好\n",
    "# 使用num_examples=None 即使用所有训练语句\n",
    "num_examples=30000 # 训练数据集大小\n",
    "input_tensor,input_lang_tokenizer,target_tensor,target_lang_tokenizer=\\\n",
    "load_dataset(path_to_file,num_examples)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(73, 'very')"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 在tokenizer.index_word字典中，包含了我们所有的词索引\n",
    "target_lang_tokenizer.word_index['love'],target_lang_tokenizer.index_word[49]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(16, 11)"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 计算句子最大长度\n",
    "max_length_input,max_length_target=max_length(input_tensor),max_length(target_tensor)\n",
    "max_length_input,max_length_target"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((30000, 16), (30000, 11))"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "input_tensor.shape,target_tensor.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "24000 6000\n"
     ]
    }
   ],
   "source": [
    "# 切分训练集与验证集\n",
    "input_tensor_train,input_tensor_val,target_tensor_train,target_tensor_val=\\\n",
    "train_test_split(input_tensor,target_tensor,test_size=0.2)\n",
    "print(len(input_tensor_train),len(input_tensor_val))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "def convert(lang_tokenizer,tensor):\n",
    "    for t in tensor:\n",
    "        if t!=0:\n",
    "            print('{} ---> {}'.format(t,lang_tokenizer.index_word[t]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "input language:index to word\n",
      "1 ---> <start>\n",
      "17 ---> se\n",
      "47 ---> estaba\n",
      "7901 ---> oscureciendo\n",
      "3 ---> .\n",
      "2 ---> <end>\n",
      "target language:index to word\n",
      "1 ---> <start>\n",
      "9 ---> it\n",
      "26 ---> was\n",
      "349 ---> getting\n",
      "554 ---> dark\n",
      "3 ---> .\n",
      "2 ---> <end>\n"
     ]
    }
   ],
   "source": [
    "print(\"input language:index to word\")\n",
    "convert(input_lang_tokenizer,input_tensor_train[23])\n",
    "print('target language:index to word')\n",
    "convert(target_lang_tokenizer,target_tensor_train[23])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 使用tf.data创建数据集\n",
    "Buffer_size=len(input_tensor_train)\n",
    "Batch_size=64\n",
    "steps_per_epoch=len(input_tensor_train)//Batch_size\n",
    "embedding_dim=256\n",
    "units=1024\n",
    "# 加一是因为用了padding（0）\n",
    "vocab_input_size=len(input_lang_tokenizer.word_index)+1\n",
    "vocab_target_size=len(target_lang_tokenizer.word_index)+1\n",
    "dataset=tf.data.Dataset.from_tensor_slices((input_tensor_train,target_tensor_train)).shuffle(Buffer_size)\n",
    "# 最后形成不了一个batch的丢弃  drop_remainder\n",
    "dataset=dataset.batch(Batch_size,drop_remainder=True)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(TensorShape([64, 16]), TensorShape([64, 11]))"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "example_input_batch,example_target_batch=next(iter(dataset))\n",
    "example_input_batch.shape,example_target_batch.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 创建encoder与decoder"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "使用的是Bahdanau注意力模型\n",
    "![img](./pic/attention1.png)\n",
    "论文中底层使用双向RNN（这里使用的单向GRU）\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "模型公式如下定义：\n",
    "- FC = 完全连接（密集）层\n",
    "- EO = 编码器输出\n",
    "- H = 解码器隐藏层状态\n",
    "- X = 解码器输入.对应于翻译目标在该时间步的tensor，经过嵌入层之后变为输入词的嵌入词向量"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- score=FC(tanh(Fc(EO)+(FC(H)))\n",
    "- attention weights=softmax(score,axis=1).注意axis=1。因为softmax默认计算最后一个轴。 因为分数 （score） 的形状是 (批大小，最大长度，1)。最大长度 （max_length） 是我们的输入的长度。因为我们想为每个输入分配一个权重，所以 softmax 应该用在这个轴上。\n",
    "- context vector = sum(attention weights * EO, axis = 1)\n",
    "- embedding output = 解码器输入 X 通过一个嵌入层。\n",
    "- merged vector = concat(embedding output, context vector)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Encoder(tf.keras.Model):\n",
    "    def __init__(self,vocab_size,embedding_dim,encoder_units,batch_size):\n",
    "        super(Encoder,self).__init__()\n",
    "        self.batch_size=batch_size\n",
    "        self.encoder_units=encoder_units\n",
    "        self.embedding=tf.keras.layers.Embedding(vocab_size,embedding_dim)\n",
    "        self.gru=tf.keras.layers.GRU(self.encoder_units,\n",
    "                                    return_sequences=True,\n",
    "                                    return_state=True,\n",
    "                                    recurrent_initializer='glorot_uniform')\n",
    "    \n",
    "    def call(self,x,hidden):\n",
    "        x=self.embedding(x)\n",
    "        output,state=self.gru(x,initial_state=hidden)\n",
    "        return output,state\n",
    "    def initialize_hidden_state(self):\n",
    "        return tf.zeros((self.batch_size,self.encoder_units))\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Encoder output shape: (batch size, sequence length, units) (64, 16, 1024)\n",
      "Encoder Hidden state shape: (batch size, units) (64, 1024)\n"
     ]
    }
   ],
   "source": [
    "encoder=Encoder(vocab_input_size,embedding_dim,units,Batch_size)\n",
    "# 样本输入\n",
    "sample_hidden=encoder.initialize_hidden_state()\n",
    "sample_output,sample_hidden=encoder(example_input_batch,sample_hidden)\n",
    "print ('Encoder output shape: (batch size, sequence length, units) {}'.format(sample_output.shape))\n",
    "print ('Encoder Hidden state shape: (batch size, units) {}'.format(sample_hidden.shape))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1, 3, 2)\n",
      "tf.Tensor(\n",
      "[[[0.09003057 0.21194157]\n",
      "  [0.24472848 0.5761169 ]\n",
      "  [0.66524094 0.21194157]]], shape=(1, 3, 2), dtype=float32)\n",
      "tf.Tensor(\n",
      "[[[0.5        0.5       ]\n",
      "  [0.5        0.5       ]\n",
      "  [0.880797   0.11920291]]], shape=(1, 3, 2), dtype=float32)\n"
     ]
    }
   ],
   "source": [
    "a=tf.Variable([[[1,1],[2,2],[3,1]]])\n",
    "a=tf.cast(a,tf.float32)\n",
    "print(a.shape)\n",
    "print(tf.nn.softmax(a,axis=1))\n",
    "print(tf.nn.softmax(a,axis=2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 161,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Attention(tf.keras.layers.Layer):\n",
    "    def __init__(self,units):\n",
    "        super(Attention,self).__init__()\n",
    "        self.W1=tf.keras.layers.Dense(units)\n",
    "        self.W2=tf.keras.layers.Dense(units)\n",
    "        self.V=tf.keras.layers.Dense(1)\n",
    "    def call(self,query,values):\n",
    "        # query是decoder隐藏层状态，values是encoder的输出\n",
    "        # 使用的 decoder的hidden-state和output计算score\n",
    "        \n",
    "        # hidden_state.shape=(batch_size,units)\n",
    "        # hidden_state_with_time_axis.shape=(batch_size,1,units)\n",
    "        # 这样方便执行加法计算分数\n",
    "        hidden_state_with_time_axis=tf.expand_dims(query,1)\n",
    "        # 分数的形状 == （批大小，最大长度，1）\n",
    "        # 我们在最后一个轴上得到 1， 因为我们把分数应用于 self.V\n",
    "        # 在应用 self.V 之前，张量的形状是（批大小，最大长度，units(设置在init函数中））\n",
    "        score=self.V(tf.nn.tanh(self.W1(values)+ self.W2(hidden_state_with_time_axis)))\n",
    "        \n",
    "        # attention_weights.shape = （批大小，最大长度，1）\n",
    "        # 注意是axis=1 在第二个维度上\n",
    "        attention_weights=tf.nn.softmax(score,axis=1)\n",
    "        \n",
    "        # contect_vector.shape=(批大小，隐藏层大小）\n",
    "        context_vector=tf.reduce_sum(attention_weights*values,axis=1)\n",
    "        \n",
    "        return context_vector,attention_weights"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 162,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Attention result shape: (batch size, units) (64, 1024)\n",
      "Attention weights shape: (batch_size, sequence_length, 1) (64, 16, 1)\n"
     ]
    }
   ],
   "source": [
    "attention_layer = Attention(10)\n",
    "attention_vector, attention_weights = attention_layer(sample_hidden, sample_output)\n",
    "print(\"Attention result shape: (batch size, units) {}\".format(attention_vector.shape))\n",
    "print(\"Attention weights shape: (batch_size, sequence_length, 1) {}\".format(attention_weights.shape))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 163,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Decoder(tf.keras.Model):\n",
    "    def __init__(self,vocab_size,embedding_dim,decoder_units,batch_size):\n",
    "        super(Decoder,self).__init__()\n",
    "        self.batch_size=batch_size\n",
    "        self.decoder_units=decoder_units\n",
    "        self.embedding=tf.keras.layers.Embedding(vocab_size,embedding_dim)\n",
    "        self.gru=tf.keras.layers.GRU(self.decoder_units,\n",
    "                                    return_sequences=True,\n",
    "                                    return_state=True,\n",
    "                                    recurrent_initializer='glorot_uniform')\n",
    "        self.fc=tf.keras.layers.Dense(vocab_size)\n",
    "        \n",
    "        self.attention=Attention(self.decoder_units)\n",
    "        \n",
    "    def call(self,x,hidden_state,encoder_output):\n",
    "        # 这个参数x是decoder的输入，对应每一个时间步的翻译目标值\n",
    "        # hidden代表的是decoder自己的hidden-state\n",
    "        # decoder-hidden-state与encoder-output两个向量迎来计算出得分，从而获得attention-weights\n",
    "        \n",
    "        # encoder_output.shape=(批大小，最大长度，隐藏层大小)\n",
    "        context_vector, attention_weights=self.attention(hidden_state,encoder_output)\n",
    "        # x是上层解码器的输入，通过嵌入层之后维度为（批大小，1，嵌入维度）\n",
    "        x=self.embedding(x)\n",
    "        \n",
    "        # x进行拼接（concatenation）之后shape为（批大小，1，嵌入维度+隐藏层大小）\n",
    "        # context_vector.shape=(batch_size,units)\n",
    "        x=tf.concat([tf.expand_dims(context_vector,1),x],axis=-1)\n",
    "        \n",
    "        # 将合并后的向量传到解码器的GRU\n",
    "        output,state=self.gru(x)\n",
    "        \n",
    "        # 输出的形状(reshape前）=(批大小，1,隐藏层大小)\n",
    "        # 输出的形状(reshape后）=(批大小,隐藏层大小)\n",
    "        output=tf.reshape(output,(-1,output.shape[2]))\n",
    "        \n",
    "        # 输出的形状 == （批大小，vocab）\n",
    "        x = self.fc(output)\n",
    "\n",
    "        return x, state, attention_weights"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 164,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(64, 1024) (64, 16, 1)\n",
      "Decoder output shape: (batch_size, vocab size) (64, 4834)\n"
     ]
    }
   ],
   "source": [
    "decoder = Decoder(vocab_target_size, embedding_dim, units, Batch_size)\n",
    "\n",
    "sample_decoder_output, a, b = decoder(tf.random.uniform((64, 1)),\n",
    "                                      sample_hidden, sample_output)\n",
    "print(a.shape,b.shape)\n",
    "print ('Decoder output shape: (batch_size, vocab size) {}'.format(sample_decoder_output.shape))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 定义优化器，损失函数"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 165,
   "metadata": {},
   "outputs": [],
   "source": [
    "optimizer=tf.keras.optimizers.Adam()\n",
    "# y_true: Ground truth values. shape = [batch_size, d0, .. dN]\n",
    "# y_pred: The predicted values. shape = [batch_size, d0, .. dN]\n",
    "# recuction=none，那么返回的损失是[batch_size, d0, .. dN-1]（(Note dN-1 because all loss functions reduce by 1 dimension, usually axis=-1.)）\n",
    "# 否则返回的损失是一个常量，\n",
    "loss_object=tf.keras.losses.SparseCategoricalCrossentropy(from_logits=True,reduction='none')\n",
    "\n",
    "def loss_function(y_true,y_pred):\n",
    "    # 标记出来padding 0 所在的位置下标\n",
    "    # 最后在与loss相乘的时候省略padding位置所产生的loss\n",
    "    mask=tf.math.logical_not(tf.math.equal(y_true,0))\n",
    "    loss=loss_object(y_true,y_pred)\n",
    "    mask=tf.cast(mask,dtype=loss.dtype)\n",
    "    loss*=mask\n",
    "    return tf.reduce_mean(loss)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 检查点"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 166,
   "metadata": {},
   "outputs": [],
   "source": [
    "checkpoint_dir='./machine_translation_checkpoint'\n",
    "checkpoint_prefix=os.path.join(checkpoint_dir,'ckpt')\n",
    "checkpoint=tf.train.Checkpoint(optimizer=optimizer,\n",
    "                              encoder=encoder,\n",
    "                              decoder=decoder)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 训练"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1. 将 输入 传送至 编码器，编码器返回 编码器输出 和 编码器隐藏层状态。\n",
    "2. 将编码器输出、编码器隐藏层状态和解码器输入（即 开始标记）传送至解码器。\n",
    "3. 解码器返回 预测 和 解码器隐藏层状态。\n",
    "4. 解码器隐藏层状态被传送回模型，预测被用于计算损失。\n",
    "5. 使用 教师强制 （teacher forcing） 决定解码器的下一/个输入。\n",
    "6. 教师强制 是将 目标词 作为 下一个输入 传送至解码器的技术。\n",
    "7. 最后一步是计算梯度，并将其应用于优化器和反向传播。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "TensorShape([64, 1, 16])"
      ]
     },
     "execution_count": 97,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tf.expand_dims(tf.random.normal((64,16)),1).shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "metadata": {},
   "outputs": [],
   "source": [
    "@tf.function\n",
    "def train_step(inp,targ,enc_hidden):\n",
    "    loss=0\n",
    "    \n",
    "    with tf.GradientTape() as tape:\n",
    "        enc_output,enc_hidden=encoder(inp,enc_hidden)\n",
    "        \n",
    "        # 在第一步，decoder-hidden=encoder-hidden老初始化\n",
    "        # 之后，decode-hidden就在每一次解码中更新了\n",
    "        dec_hidden=enc_hidden\n",
    "        \n",
    "        dec_input=tf.expand_dims([target_lang_tokenizer.word_index['<start>']]*Batch_size,1)\n",
    "        \n",
    "        # 教师强制-将目标词作为下一个输入\n",
    "        for t in range(1,targ.shape[1]):\n",
    "            # 将编码器输出传到解码器\n",
    "            predictions,dec_hidden,_=decoder(dec_input,dec_hidden,enc_output)\n",
    "            \n",
    "            loss+=loss_function(targ[:,t],predictions)\n",
    "            \n",
    "            # 使用教师强制\n",
    "            dec_input=tf.expand_dims(targ[:,t],1)\n",
    "        \n",
    "        batch_loss=(loss/int(targ.shape[1]))\n",
    "        \n",
    "        variables=encoder.trainable_variables+decoder.trainable_variables\n",
    "\n",
    "        # 对每一个变量计算梯度\n",
    "        gradients=tape.gradient(loss,variables)\n",
    "        \n",
    "        # Apply gradients to variables\n",
    "        optimizer.apply_gradients(zip(gradients,variables))\n",
    "        return batch_loss\n",
    "            "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1 Batch 0 loss: 3.029433488845825\n",
      "Epoch 1 Batch 100 loss: 2.1914610862731934\n",
      "Epoch 1 Batch 200 loss: 1.7751097679138184\n",
      "Epoch 1 Batch 300 loss: 1.5683094263076782\n",
      "Epoch 1 Loss 1.9404\n",
      "Time taken for 1 epoch 428.19849133491516 sec\n",
      "\n",
      "Epoch 2 Batch 0 loss: 1.5071711540222168\n",
      "Epoch 2 Batch 100 loss: 1.511332631111145\n",
      "Epoch 2 Batch 200 loss: 1.4215682744979858\n",
      "Epoch 2 Batch 300 loss: 1.1929481029510498\n",
      "Epoch 2 Loss 1.3614\n",
      "Time taken for 1 epoch 412.7278311252594 sec\n",
      "\n",
      "Epoch 3 Batch 0 loss: 1.0165706872940063\n",
      "Epoch 3 Batch 100 loss: 0.9832627177238464\n",
      "Epoch 3 Batch 200 loss: 0.970638632774353\n",
      "Epoch 3 Batch 300 loss: 0.8129992485046387\n",
      "Epoch 3 Loss 0.9585\n",
      "Time taken for 1 epoch 409.06610584259033 sec\n",
      "\n",
      "Epoch 4 Batch 0 loss: 0.654787540435791\n",
      "Epoch 4 Batch 100 loss: 0.635719895362854\n",
      "Epoch 4 Batch 200 loss: 0.7151980400085449\n",
      "Epoch 4 Batch 300 loss: 0.6077576279640198\n",
      "Epoch 4 Loss 0.6469\n",
      "Time taken for 1 epoch 413.9337651729584 sec\n",
      "\n",
      "Epoch 5 Batch 0 loss: 0.41980913281440735\n",
      "Epoch 5 Batch 100 loss: 0.3786979615688324\n",
      "Epoch 5 Batch 200 loss: 0.47265976667404175\n",
      "Epoch 5 Batch 300 loss: 0.4130556583404541\n",
      "Epoch 5 Loss 0.4378\n",
      "Time taken for 1 epoch 405.1149249076843 sec\n",
      "\n",
      "Epoch 6 Batch 0 loss: 0.2715241611003876\n",
      "Epoch 6 Batch 100 loss: 0.28385868668556213\n",
      "Epoch 6 Batch 200 loss: 0.3162198066711426\n",
      "Epoch 6 Batch 300 loss: 0.305117130279541\n",
      "Epoch 6 Loss 0.3021\n",
      "Time taken for 1 epoch 401.84941697120667 sec\n",
      "\n",
      "Epoch 7 Batch 0 loss: 0.20939844846725464\n",
      "Epoch 7 Batch 100 loss: 0.19741122424602509\n",
      "Epoch 7 Batch 200 loss: 0.20980851352214813\n",
      "Epoch 7 Batch 300 loss: 0.2215273231267929\n",
      "Epoch 7 Loss 0.2182\n",
      "Time taken for 1 epoch 409.911328792572 sec\n",
      "\n",
      "Epoch 8 Batch 0 loss: 0.19710057973861694\n",
      "Epoch 8 Batch 100 loss: 0.11117908358573914\n",
      "Epoch 8 Batch 200 loss: 0.17623507976531982\n",
      "Epoch 8 Batch 300 loss: 0.16273227334022522\n",
      "Epoch 8 Loss 0.1578\n",
      "Time taken for 1 epoch 410.6694779396057 sec\n",
      "\n",
      "Epoch 9 Batch 0 loss: 0.09430627524852753\n",
      "Epoch 9 Batch 100 loss: 0.12324800342321396\n",
      "Epoch 9 Batch 200 loss: 0.14278894662857056\n",
      "Epoch 9 Batch 300 loss: 0.10942284017801285\n",
      "Epoch 9 Loss 0.1223\n",
      "Time taken for 1 epoch 415.9951171875 sec\n",
      "\n",
      "Epoch 10 Batch 0 loss: 0.0808326005935669\n",
      "Epoch 10 Batch 100 loss: 0.11886684596538544\n",
      "Epoch 10 Batch 200 loss: 0.08729703724384308\n",
      "Epoch 10 Batch 300 loss: 0.09437823295593262\n",
      "Epoch 10 Loss 0.0995\n",
      "Time taken for 1 epoch 406.6334636211395 sec\n",
      "\n"
     ]
    }
   ],
   "source": [
    "EPOCHS=10\n",
    "for epoch in range(EPOCHS):\n",
    "    start=time.time()\n",
    "    \n",
    "    enc_hidden=encoder.initialize_hidden_state()\n",
    "    \n",
    "    total_loss=0\n",
    "    \n",
    "    for (batch,(inp,targ)) in enumerate(dataset.take(steps_per_epoch)):\n",
    "        batch_loss=train_step(inp,targ,enc_hidden)\n",
    "        total_loss+=batch_loss\n",
    "     \n",
    "        if batch%100==0:\n",
    "            print(f'Epoch {epoch+1} Batch {batch} loss: {batch_loss.numpy()}')\n",
    "        # 每 2 个周期（epoch），保存（检查点）一次模型\n",
    "    if (epoch + 1) % 2 == 0:\n",
    "        checkpoint.save(file_prefix = checkpoint_prefix)\n",
    "\n",
    "    print('Epoch {} Loss {:.4f}'.format(epoch + 1,\n",
    "                                      total_loss / steps_per_epoch))\n",
    "    print('Time taken for 1 epoch {} sec\\n'.format(time.time() - start))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 翻译"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- 翻译的时候类似于循环训练，但是我们不使用教师强制（teaching force）来将正确的目标推送到解码器。每个时间步的解码器输入是之前的预测，隐藏层状态与编码器输出\n",
    "- 当模型预测到结束标记（< end >)的时候停止输出\n",
    "- 我们需要存储每一个时间步的attention weights，方便绘制图像"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 177,
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate(sentence):\n",
    "    attention_plot=np.zeros((max_length_target,max_length_input))\n",
    "    # preprocess_sentence\n",
    "    # 在单词符号之间插入空格\n",
    "    # 除了 (a-z, A-Z, \".\", \"?\", \"!\", \",\")，将所有字符替换为空格\n",
    "    sentence=preprocess_sentence(sentence)\n",
    "    \n",
    "    # 将输入文本转为数字编码\n",
    "    inputs=[input_lang_tokenizer.word_index[i] for i in sentence.split(' ')]\n",
    "    # 对输入进行pudding\n",
    "    inputs=tf.keras.preprocessing.sequence.pad_sequences([inputs],maxlen=max_length_input,padding='post')\n",
    "    \n",
    "    # 可以将tf常量，数组，numpy数组转为tensor\n",
    "    inputs=tf.convert_to_tensor(inputs)\n",
    "    \n",
    "    result=''\n",
    "    \n",
    "    enc_hidden=tf.zeros((1,units))\n",
    "    \n",
    "    enc_output,enc_hidden=encoder(inputs,enc_hidden)\n",
    "    \n",
    "    dec_hidden=enc_hidden\n",
    "    # 添加一个维度，变为（1，1）\n",
    "    dec_input=tf.expand_dims([target_lang_tokenizer.word_index['<start>']],0)\n",
    "    \n",
    "    \n",
    "    for t in range(max_length_target):\n",
    "        predictions,dec_hidden,attention_weights=decoder(dec_input,dec_hidden,enc_output)\n",
    "        \n",
    "        # 存储注意力权重，从而进行绘图\n",
    "        attention_weights = tf.reshape(attention_weights, (-1, ))\n",
    "        attention_plot[t]=attention_weights.numpy()\n",
    "        \n",
    "        predicted_index=tf.argmax(predictions[0]).numpy()\n",
    "        result+=target_lang_tokenizer.index_word[predicted_index]+' '\n",
    "        \n",
    "        if target_lang_tokenizer.index_word[predicted_index] == '<end>':\n",
    "            return result, sentence, attention_plot\n",
    "\n",
    "        # 预测的 ID 被输送回模型\n",
    "        dec_input = tf.expand_dims([predicted_index], 0)\n",
    "\n",
    "    return result, sentence, attention_plot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 217,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 绘制注意力权重图\n",
    "def plot_attention(attention_plot,sentence,predicted_sentence):\n",
    "    fig=plt.figure(figsize=(3,3))\n",
    "    ax=fig.add_subplot(1,1,1)\n",
    "    ax.matshow(attention_plot,cmap='viridis')\n",
    "    \n",
    "    fontdict={'fontsize':14}\n",
    "    \n",
    "    ax.set_xticklabels([''] + sentence, fontdict=fontdict, rotation=90)\n",
    "    ax.set_yticklabels([''] + predicted_sentence, fontdict=fontdict)\n",
    "\n",
    "    ax.xaxis.set_major_locator(ticker.MultipleLocator(1))\n",
    "    ax.yaxis.set_major_locator(ticker.MultipleLocator(1))\n",
    "\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 218,
   "metadata": {},
   "outputs": [],
   "source": [
    "def translate(sentence):\n",
    "    # attention-plot维度是 （max_length_target，max-length-input）\n",
    "    result,sentence,attention_plot=evaluate(sentence)\n",
    "    \n",
    "    print(f'Input is: {sentence}')\n",
    "    print(f' My Translation is: {result}')\n",
    "    \n",
    "    # 截去没有用的维度，\n",
    "    attention_plot=attention_plot[:len(result.split(' ')),:len(sentence.split(' '))]\n",
    "    \n",
    "    plot_attention(attention_plot,sentence.split(' '),result.split(' '))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 从检查点恢复模型"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 219,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.training.tracking.util.CheckpointLoadStatus at 0x1508282b0>"
      ]
     },
     "execution_count": 219,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 恢复检查点目录 （checkpoint_dir） 中最新的检查点\n",
    "checkpoint.restore(tf.train.latest_checkpoint(checkpoint_dir))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 220,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Googole translation: It's cold outside.\n",
      "Input is: <start> hace frio afuera . <end>\n",
      " My Translation is: it s cold outside . <end> \n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 216x216 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "print(\"Googole translation: It's cold outside.\")\n",
    "translate('Hace frío afuera.')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 221,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Input is: <start> ¿ todavia estan en casa ? <end>\n",
      " My Translation is: are you still at home ? <end> \n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 216x216 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "print(\"Googole translation: are you still at home ?\")\n",
    "translate('¿ todavia estan en casa ? ')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 226,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Googole translation: because the virus I can't go out\n",
      "Input is: <start> no puedo salir porque el virus <end>\n",
      " My Translation is: i can t go anywhere . <end> \n"
     ]
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAP0AAAD0CAYAAABQOiA0AAAABHNCSVQICAgIfAhkiAAAAAlwSFlzAAALEgAACxIB0t1+/AAAADh0RVh0U29mdHdhcmUAbWF0cGxvdGxpYiB2ZXJzaW9uMy4xLjAsIGh0dHA6Ly9tYXRwbG90bGliLm9yZy+17YcXAAAdYElEQVR4nO3dd7wcZb3H8c83ISSSEJAQqtQISBMhkSI1gFJUrnoRhEAoUgQUAhfhIhfBl9JCUXyBQkRKQNrl0gWUehOpl04AgWAqgUAgEFJJ+d0/nuckk8menC2zM3syv/frta/szuz+9tmT/e0887SRmeGcK48uRRfAOZcvT3rnSsaT3rmS8aR3rmQ86Z0rGU9650rGk965kvGkd65kPOmdKxlPeudKxpM+Z5I2kvSopC2LLosrJ0/6/B0G7AYcWXA5XEnJJ9zkR5KAscBDwHeBtcxsfqGFcqXjR/p8DQRWBE4E5gH7FlscV0ae9PkaDNxuZjOBmwlVfedy5dX7nEjqCbwHfNvMRkr6GvAUoYo/tdjSuTLxI31+/h2YYmYjAczsJeBt4EeFlqqTkbSPpPskvS5pnbjtKEl7FF22ZpPUU9JgSSs1EseTPj+HAjemtt2IV/GrJmkQcBvhx3IDoFvc1RU4rahy5egA4FrCd6luXr3PQTwijQE2NbO3E9u/RGjN38zM3iqoeJ2GpJeB883sFkmfAVuZ2b8kbQX83cxWL7iITSXpcWA1YKaZDag3znKZlci1y8wmUOFvbWYTK2137dqI0A6SNh3onXNZciVpfeAbwLbA05I2M7PX64nl1fucSFo39tNX3Jd3eTqpScDGFbbvAryTc1nydigwMrYF3U8Dp4We9PkZA/RNb5TUJ+5rKZJ6xR6HVjIM+L2kHePjdSQdBgwF/lhcsXIxGLgh3r8RGNTeQaQjnvT5EVCpAaUXMDvnsrRL0gmSxgOfAtMkjZN0fNHlAjCzocAdhBGNPYHHgCuBK83siiLL1kySvgGsCfx33HQfsAKwZ13xvCGvuST9Pt49gdDyOjOxuyvhHO1zM9sx/dq8SfoFcAZwMfCPuHln4BTgPDO7oKiyJUlaAdiMcNB63cymF1ykppJ0FdDLzAYltl0JrJjcVnU8T/rmkvRYvLsroRHq88Tuzwmt9xcnW/WLEo/wp5vZzantgwhJv14xJSsvSd2B94GDzOzBxPadgL8Bq9f6o+dJn4N47nUbcKSZfVZ0edojaTawhZmNTm3fCHjVzHoUU7KF5bhnafvNbL+8ypIXSasS5mjcYKlklXQI8LCZvV9LTD+nz0cX4HvAOkUXpANvAQdX2H4w8GbOZanko9RtGmGQzi7AlALL1TRmNsXMhqcTPu67sdaEB+8jzoWZzZc0Dli+6LJ04BzgNkm7AE8QGh53Ipya/LDAcgFgZkdU2i7pEqBla1Ctxqv3OYldSwcBh5hZyx6VJPUHTgY2JfQ4vA5cYmYvFlqwpZC0MfAPM1ut6LJkRdIYKvf2LMHMNqwlth/p83MqoSr6rqSJwIzkTjP7aiGlSjGz54FDii5HjTYpugBNcHnifi9CD8qzLBqRuAOh5+eSWgN70ufn9qILUEktowHNbHwzy9KRRPfnwk2E/ut9gGvyL9HiJG0GzDezN+PjbxJGzr0GDK1llSQzW5jMkq4DLjSz81Lvdwawec3l9Op9uUlaQPXVyK5NLs5SJbo/2ywAPgQeBa4xs3n5l2oRSU8Bl8UJQV8iNIw+DnyV0Pp+Rp1xpwHbVOhV+TLwgpnVNO/Aj/Tu64n7GxOGtF7J4tXIY4HTcy7XEsxsYNFl6MCmwAvx/g+BZ8xsX0kDCQOz6kp6wqngbsDo1PbdWHywV1U86XMiaXngTEJj3rosmgsOFHcUjefwAEi6FDjZzJKnIo9KehM4ibDEl2tfVxYNvtqDMDEGwmSgRqb9/ha4QtIA4Om4bXvCqcM5tQbzpM/Pr4EDgfMJ/4k/B9YnrJxzVnHFWsy2wCsVtr8C9K8lkKRuhKG8g9vOcRsVq/fVnorsnsV71mgUcJyk+whJ33ZkX5sGxhGY2VBJYwk/vAfEzW8Ah5nZbbXG86TPzwHAT8zsQUkXA3eb2TuS3gC+CVxVbPGAMCT4eGBIavvxwLhaApnZXEkbUGWSVukNYBBhWOozcdu2wBrATUDRy4mfDtxF6Km53sxejdv3I7S81y0md80JXok35OVE0kzgK2Y2XtJ7wHfM7PmYGC/X2hjTDJL2Bu4kJHhbNXI7Qo3kB2b2QI3xLgIws59nVL7fEqrQJyVHqEn6HeG7fFIW79MISV2B3snFTuMCGDPN7IMM4q9MaiStmX1cSww/0udnPLBW/Hc0sBfwPKGhbFaB5Voo1kI2IhzZv0LoEruDMHV1Qh0hexLmfX+T8FnTYxNOrDHeYGCHCkNS/0D4kSo86WO33NTUtrGNxJS0HqFxdSCLtwW1TdeuqT3Ikz4/dxLO854GLgNulnQ04XzvoiILlhSX8PpFRuGSrdnpUWP1VDEFbEnoCktqiesCNnFC0LXAyoRLoU2iwVMmT/qcJPtozex2SROAHYG3zOy+4kq2uHhhzWMJSfpjM3tP0veAcbUOxW1CF9s1wNWxNpJsxT6NkBhF+yj1uBuwFWGi1R0NxN0W2N7MRjUQYyFP+pzESSxPtg0gMbNngGckLSdpFzMbUWwJQdK3gHuABwi1ki/EXf2AwwkzBYt0GvABoRrfNjrtPeAC6hiOmrUmTggaA3Rv4PWL8Ya8nEiaD6yZbsyJa+R9UPRot1iWZwitzn9ILTHdH7jXzNaqIsY9hElF07Ks7krqQmhnGGdmMyT1jjGmVRujKI1OCJK0O/CfwPHpUXn18CN9ftpbI68PqQauAm3OogElSR8Dq1QZ4yMWfc50dbcRBrxEWCZrdGdI9oRGJwTdTTjSvylpDuHipwv5MNwWkzjaGXBj/E9r0xXYAngy94JVNpXQsDg2tX0bYGI1AZJV3Paqu/UwM4sjA/uy5HDUltDECUE/beC1S/Ckb762o50ISZXsnvucMGrtT3kXqh03ARdJOoDwI7WcpF0JC2W2QkPZaYTy/ZQwtqHVzk3TvQhtE4JOpoGkN7PrGylUmp/T50TS2YQFMFulKr+EOHT2OsLQYBG+tCL8GBxezdTQjs7jk2rtwortDD0Ig1PmAclaU83V3KzFVXrn1DKFtobYqxMueNEPOMvMpsT1/yeZWU3XTfCkz0lsiMLMFsTHawDfISzh3CrVewAk9QO2JiTXi7Ws1Cup6hpBrdX/uPrQ0uJlekSsRRyJN5vQ+FnX5aaWErs/8AihFX9zwsjOf0k6B9jYzCqta9h+PE/6fEh6AHjQzC6T1Av4J2HEWi9Cf/jwQgvoGiZpNLC/hUtPZRn3MWCEmZ2d6lXZAbjFalya3M/p89OfRZdT/gGLVnIdRJigUXPSxzXRBxFatI2wQsvNZjZnqS9sP166IWoxdQybzVzWnzljvwYukJT1Ooj9gR9X2P4edUzZ9aTPz4rAJ/H+t4A740y0R4GaL8kUl2Z6AFgJaJvNdTTwK0l7m9kbdZQx3RDVjdA3vhyLhtPWWs6BLFpDYLHVgGud/ho/84OEK9Rm9Zmz1Kx1EGcBX6yw/SuEwUo18aTPz3hgR0n3EibbtC0pvQp1rH5CGL//EnBoW591HLByI/C7+B41qTRsVlIP4M/AyFrjSTqcMFHkTsIqL3cTVufZIJazVpcBL5LhZ85Ys9ZBvBs4W1Lbd8bizL0Lgf+pOZqZ+S2HG2E8+1xCt91LQJe4/UTg0TrizQQ2r7B9S2BGxmXfDJhQx+tGAUfF+58BG8b7lwMXtPJnbqUboWbzD8Ip4XzgXULvxQigZ63x/EifEzO7StJzhGruQxZb8QlLKdWzcs5swsyrtJXI/iq4fQkNjrXaEHg43p+TiHE5YcHI/6wxXsOfWdIPqn0zM2tkkkxmLNRqdorDcbch9Kq8YGYPL/2VlXnS50DSSsBXzWwkYV550ieEC0rU6l7gT3F6btuMsx0IK/BU3VeeKucp6U2EEWWDqDw8tyMfEdoyIBydtiAsvdWHRZN5apHFZ662Cl7VPPW4Uu2GFvrNP2Mp016tjnEEye+OmT1KWPm3bd+OhC7fqe0GqMCTPh8LgAck7WVmT7RtlPQ1wn/i2nXEPAm4nnCu3TYYpCvh/O/kOsv5s9TjthFl1xLW9qvVSEKj5auEpZ5+HxfU2INwjflaLe0zp5f4qsjMsr5+489YNIMu0+GyUebfHe+nz4mkvwDTzezYxLaLCYMr6r7aalz7fOElqCyDWVgxbi8Aa+Da75JWAXqY2aQ4OOnnxDUEgN+Y2SdLDdB+3LbPDOEzv9NAGfcBTiCciuxlZhMkHQWMMbNHaox1J3ADcJ+Zfd7R82uIm+l3x69am5/hwA/jUNe2EXoHE4a91kXSgYS+/x8DRwGXSrqnlqGwFWIOUbhO/afAp5ImSDpZkuoItwaxeh/bMF4gHBU/ps755ZKGEI5wd8Xb4/WWT9IgQg3kbUKPQttSVF1ZNKaiFrMI/8+TJf0prqGQhWy/O0W3TJblRviBnUhYYBLCCrhTgG51xruI0Bvw9/iff23yVmfMoYQ2hjOB3ePtTEKPw9A64j0F/Cje/xKh3/r++Hc4vwXK93KifMneha2AyXX+DVcgXAvwfsKEqnGEU6Mleh0K++5k/eX221L/8y4E7or3hwNXNBBrMmHIZ5bl+7hSTGB/4KM64n1CqIJCaGd4LN4fCIxtgfLNBNaL95NJ3w+YlcHfsy/hPH8UMK9VvjvekJev4cDzktYBvk9o0KpXF0J/f9bau9hFPaeCzbjiS5blm0QYLJRe038XQhnrFgc17U4YMLQxUM9qwkmZfXf8nD5HZvYaoSX7JmCimTVyAYRhZH9J6eGERq204wgNVLVqu+LLzoQv6YNxe71XfMm6fMMIPQo7xsfrxJl8Q4E/1hpMUhdJ35J0PaEm9kfC+Pg9zWyDOsq3UJbfHT/S5+8GwpDRMxuMszJwcOwCe4Vwfr+Q1Tc5pnuMuReLX+xiLeAvyQk5VcbP+oovmZbPwuWiViJ0H/YAHiMMIrrYzGqeD0GoOaxEmBNxBBm34pPRd8e77HIWu7F+BlxlZu83ECd92eYkszqu5dZBzLriK8MrvjSjfDHuCoShxl0IXYB1dVNKOga4zersiqwifjbfHU9658rFz+mdKxlPeudKxpO+IPH8rzTxmhGz1eM1I2YW8Tzpi5P1F6zV4zUjZqvHa0ZMT3rnXG289T5Dy6u79aBnVc+dyxy6ZXdNwpaP14yYrR6vGTGrjTebGXxucypOQvLBORnqQU+2UyMja53LxjNLmRXs1XvnSsaT3rmS8aR3rmQ86ask6TpJ9xVdDuca5Q151TuJsA6dc52aJ32VzOzTosvgXBa8el8lr967ZYUnvXMl49X7BsUJEMcA9GCFgkvjXMf8SN8gMxtmZgPMbEDWQzidawZPeudKxpPeuZLxpHeuZDzpnSsZb72vkpkdXnQZnMuCH+mdKxlPeudKxqv3WZJQ9+z66iee3D+zWG1GnfiHTOPtvcF2mcYDYP78TMPZguyXhFPXrpnGs3lzO35STQHb3+VHeudKxpPeuZLxpHeuZDzpnSsZT3rnSsaT3rmS8aR3rmQ86Z0rGU9650pmmUx6Bf8h6W1JcyRNlHR+3HeBpDclzZI0VtJQST0Srz1H0ihJP5L0jqTPJN0ladXiPpFz2VlWh+GeBxwHnAKMAPoCW8d9M4AjgXeBzYArgTnAWYnXrw8cCHwf6AncApwLHNv8ojvXXMtc0kvqBZwMDDGza+Lm0cBTAGb268TTx0o6DziVxZN+OeDwtrXuJQ0Djmjn/XxhTNepLHNJTzh6dwcqXqtX0v7AEODLQC+ga7wljUtd3GISsFqleGY2DBgG0LtLn+xndjiXsWXxnL7dS09J2p5QVf8b8F1Clf+/gG6pp6anPBnL5t/KldCyeKR/nXCOvgfwdmrfjsC7ySq+pPVyLJtzhVvmkt7MPpN0GXC+pDmEhrw+QH/gLWBtSYMI5/h7AQcVVljnCrDMJX10BjCV0Dj3JWAyMNzM/ijpIuB3wBeAvwO/BLJdWcK5FiYzb3vKSu8ufWz77vtkFs9XzslGGVfOeWbBw0yzjyu2b3njlHMl40nvXMksq+f0hZCElsvuT9pn1LzMYrV5YvaCTOPN+8bmmcYDWP6VsZnGsxkzM40HoOWXzzTe/OnZntIsjR/pnSsZT3rnSsaT3rmS8aR3rmQ86Z0rGU9650rGk74Dkh6XdHnR5XAuK570zpWMJ/1SSLoO2BU4QZLF2/qFFsq5BvmIvKU7CdgY+Cfwi7jtw+KK41zjPOmXwsw+lfQ5MNPM3q/0nMXWyFPPPIvnXF28et8gMxtmZgPMbMDyi1bSdq5ledI7VzKe9B37nCVXy3Wu0/Kk79hYYFtJ60taVZL/zVyn5l/gjl1MONq/Tmi5X7fY4jjXGG+974CZvQXsUHQ5nMuKH+mdKxlPeudKxpfAztBKXfrY9j32zSyezc92PTuArquukmm8j6/JfkDS1P+reNnAuvW77r1M4wEs6JXxmIx3JmQa7umZ9/Hp/Cm+BLZzzpPeudLxpHeuZDzpnSsZT3rnSsaT3rmS8aR3rmQ86Z0rmVImvaSekoZLmi5psqQzJN0X18RD0hclXS9pqqRZkh6WlP2VGp0rQCmTHriEsODl94Hdga2AnRP7rwO2A/4N2BaYCTwo6Qv5FtO57JVulp2kXsCRwGAzeyhu+zEwMd7fCNgP2NXMRsRthwLjgUHA1UWU27mslPFI3w/oBjzbtsHMZgCj4sNNgQXAU4n9nwKvApulg0k6RtJzkp77nDnNLLdzmShj0rdNQmhvplHFSQrtvWaxhTHp3nDhnGu2Mib9aGAu4VwdAEkrAFvEh68T/i47JPb3BraM+5zr1EqX9GY2HbgGuFDSHpI2I5yndwm77W3gbuAqSTtL2hK4EZgG3FRUuZ3LSuka8qJTgZ7APcB04LfA6sDsuP8I4Hdxfw/gCWBvM5uVf1Gdy1Ypkz4e7Q+NNyR1B4YA98f9U4HDCiugc01UyqSXtDWhlf5ZYEXg9PjvrUWWy7k8lDLpo1OATYB5wEvALmY2sdgiOdd8pUx6M3sRGFB0OZwrQimTvlnMjAWzZ3f8xALNe6/ixXfr9sXBfTONB3DI/z7b8ZNqcOvz+2QaD2BWn2yvdNZ3wuRM4zGr/eEmpeuyc67sPOmdKxlPeudKxpPeuZLxpHeuZDpl0ks6R9Kojp/pnEvrlEnvnKufJ32CpOWLLoNzzVZV0kvaW9LIuFDkx5L+JmnTuG99SSbp3yU9JGmmpNclfTPul6TRkk5Nxdwovm4bSRdKeiCx7+i478DEticknZmK8SNJ70j6TNJdklZN7T8ilmW2pLcknSypS2K/STpB0h2SZgDnxe2bSfprjPuBpJslrVH1X9W5Flbtkb4nYarptsBuwKfAvakj47nA7wmLTP4fcIukXhauhf1nwrp0SUcCL5nZC8DjwE6S2kYI7gZMAQbCwkUuvh6f12Z94EDC4pbfAraOZSC+5mhCEv+SMLnmPwgTa45PleNswuy6LYErJK0JjCAsn7UtsCfQC7gn+YPhXGdV1ZfYzP4n3t42s1cI8803ILH6DPBbM7s3LkLxC2AV4Gtx37XARpK2B5DUFRhM+DEAGEmYt/71+HhXwoq1A+PjHQmr3STHZy4HHG5mr5jZU8AwYI/E/rOA08zsdjMbY2b3AhewZNLfamZXm9m/zGwMcBzwspmdbmZvxM87OJZtifH6yTXy5voaea4TqLZ630/STbEqPQ2YHF+7buJpryTuT4r/rgZgZu8D97HoaL830Af4S9w/HXgB2C2uRtsbuBxYV9JahCP/k2Y2N/Ee4+KClcn3XC2Wty+wDmH1m+ltN0LS90t9vOdSj/sDu6ReNyHuS792sTXyuvkaea4TqHbCzb3Au8Cx8d95hPXiktX7hQlpZiYJFv9RuRq4SdIQQvLfEReraPM44cg+BRhpZtMlPUtI+N2IC1xUer+2t028X9u/PwGe7OCzzUg97gL8lbC6TlrGsyKcy1+HSS+pD+Gc+AQzeyxu26aa16Y8SFhn7ifAd4F9U/sfB34KfMKic/fHgW8TqtanVftGZjZZ0rtAPzMbXmM5XwAOINQk0j8sznV61VTvpxKOvkdL+rKkXYErCUf7qpnZfMKClOcTaguPpJ4yklBz+AHwWNz2OKGxLn0+X41zgNNii/0mkraQNFjSGR287gpgJeBWSdtJ2lDSnpKGSVqxxjI413I6THozW0BIvK8SWrSvIDSS1dNqdQ0hsa+NrfrJ95kOPE+obr8YNz9F+HFJn893yMyuJpxGHAq8TPhROQYY08HrJhEaDhcQaievET7zHOr7zM61lKqq6Gb2KIvWhW/TK3F/iRn7ZlZpFv8awHzCteIqvc/2qcezCa366eedQziSJ7ddl45rZjcDN1d6r6WUkdgDsX97r3OuM8tl5Zy42uw6wG+AO81sfB7v65xbUl6DTQ4C3iR0052S03s65ypQ6tTaNaC3VrHttEfHT3RLtdz663b8pFrMm59tPGDSfutlGu+O04dmGu97357Cq6/MrXj66sNKnSsZT3rnSsaT3rmS8aR3rmQ86Z0rGU9650rGk965kvGkd65kPOmdKxlPeudKxi9V3SBJxxCm7NKDFQoujXMd8yN9g3yNPNfZeNI7VzKe9M6VjCd9FST9VNI/iy6Hc1nwpK/OqsAmRRfCuSx40lfBzM5pbz095zobT3rnSsaT3rmS8aR3rmR8RJ5rOQs+mJJpPJuf/cKYa942O9N43+1d9VXbqjLmw0vb3edHeudKxpPeuZLxpHeuZDzpnSuZUia9pFMljS26HM4VoZRJ71yZtVzSS+otaeWc37OvpCUuie3csqglkl5SV0l7SboJeB/YKm5fSdIwSR9I+kzS/0oakHjd4ZKmS9pD0ihJMyQ9JmmDVPzTJL0fnzsc6JUqwr7A+/G9dmzyx3WuUIUmvaTNJQ0FxgO3AjOAvYERkgT8FVgb+A6wNTACeFTSmokw3YEzgCOBHYCVgSsT73EA8BvgbGAbwiWz05fLvhE4GFgReEjSaEm/TP94OLcsyD3pJfWRdKKk54AXga8AQ4DVzexoMxth4frZA4GvAfub2bNmNtrMzgL+BRyaCLkccEJ8zivAxcBASW2fbQhwvZldZWZvmdm5wLPJMpnZfDO738wOAlYHzovv/3asXRwpKV07cK5TKuJI/zPgMmAOsJGZ7Wdm/21mc1LP6w+sAHwYq+XTJU0HtgD6JZ43x8zeTDyeBHQjHPEBNgWeSsVOP17IzD4zs2vMbCDwdWA14M/A/pWeL+kYSc9Jem4u6Y/gXOspYuz9MGAuMBh4TdKdwA3AI2aWHCTdBZgM7FwhxrTE/XmpfZZ4fc0kdQe+TahN7Au8Rqgt3F3p+WY2jPCZ6K1VrNJznGsluR/pzWySmZ1rZpsAewLTgVuAiZIukbR1fOoLhKr2gli1T94+qOEt3wC2T21b7LGCnSRdRWhIvBwYDfQ3s23M7DIzm1r7p3Wu9RTakGdmT5vZccCahGr/xsCzknYGHgaeAO6WtI+kDSTtIOlXcX+1LgMOk3S0pI0knQFsl3rOIcDfgd7AQcA6ZvZzMxvV4Ed0ruW0xNTaeD5/O3C7pNWA+WZmkvYltLz/iXBuPZnwQzC8hti3StoQOJfQRnAPcClweOJpjwBrmNm0JSM4t2xRaCh3WeitVWw77VF0MTq9Litke6WgZsyn77Jitp0544/Kdt3VMddeyqz3JlRc17ElBuc45/LjSe9cyXjSO1cyLdGQ51zSgpkziy5Ch+bPyXYg1toXPJlpvIk2o919fqR3rmQ86Z0rGU9650rGk965kvGkd65kPOmdKxlPeudKxpPeuZLxpHeuZDzpnSsZH4bbIEnHAMcA9CDbKaHONYMf6RtkZsPMbICZDehG96KL41yHPOmdKxlPeudKxpPeuZLxpHeuZDzpnSsZT3rnSsaT3rmS8aR3rmT8YhcZkvQhMK7Kp68KTMnw7Vs9XjNitnq8ZsSsNt56Zta30g5P+oJIes7MBpQlXjNitnq8ZsTMIp5X750rGU9650rGk744w0oWrxkxWz1eM2I2HM/P6Z0rGT/SO1cynvTOlYwnvXMl40nvXMl40jtXMv8PHL84xCocDLoAAAAASUVORK5CYII=\n",
      "text/plain": [
       "<Figure size 216x216 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "print(\"Googole translation: because the virus I can't go out\")\n",
    "translate('No puedo salir porque el virus')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
