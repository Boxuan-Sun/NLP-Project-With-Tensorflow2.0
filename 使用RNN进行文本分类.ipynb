{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "import tensorflow_datasets as tfds\n",
    "import matplotlib.pyplot as plt\n",
    "import os\n",
    "os.environ['TF_CPP_MIN_LOG_LEVEL'] = '1'\n",
    "os.environ['TF_CPP_MIN_LOG_LEVEL'] = '2'\n",
    "os.environ[\"KMP_DUPLICATE_LIB_OK\"]=\"TRUE\"\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_graphs(history,string):\n",
    "    plt.plot(history.history[string],'b',label='Training '+string,)\n",
    "    plt.plot(history.history['val_'+string],'y',label='Val '+string)\n",
    "    plt.xlabel('Epochs')\n",
    "    plt.ylabel(string)\n",
    "    plt.legend()\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 设置输入"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "as_supervised: bool, if True, the returned tf.data.Dataset will have a 2-tuple structure (input, label) according to builder.info.supervised_keys. If False, the default, the returned tf.data.Dataset will have a dictionary with all the features.\n",
    "\n",
    "with_info: bool, if True, tfds.load will return the tuple (tf.data.Dataset, tfds.core.DatasetInfo) containing the info associated with the builder.\n",
    "\n",
    "ds_info: tfds.core.DatasetInfo, if with_info is True, then tfds.load will return a tuple (ds, ds_info) containing dataset information (version, features, splits, num_examples,...). Note that the ds_info object documents the entire dataset, regardless of the split requested. Split-specific information is available in ds_info.splits."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset,info=tfds.load('imdb_reviews/subwords8k',with_info=True,\n",
    "                      as_supervised=True)\n",
    "train_dataset,test_dataset=dataset['train'],dataset['test']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "dict_items([('test', <_OptionsDataset shapes: ((None,), ()), types: (tf.int64, tf.int64)>), ('train', <_OptionsDataset shapes: ((None,), ()), types: (tf.int64, tf.int64)>), ('unsupervised', <_OptionsDataset shapes: ((None,), ()), types: (tf.int64, tf.int64)>)])"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset.items()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Vocabulary size:8185\n"
     ]
    }
   ],
   "source": [
    "# with_info=True 返回了dataset_info。\n",
    "# info的features['text']中包含了编码器\n",
    "encoder=info.features['text'].encoder\n",
    "print(f'Vocabulary size:{encoder.vocab_size}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "此文本编码器将可逆地对任何字符串进行编码，必要时返回字节编码。\n",
    "可能是 因为词汇表只有8185.可能有些词语没有收录，就只能对字节编码了。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Encode string is: [4025, 222, 943, 2327, 2934, 90, 45, 414, 12, 96, 523, 37, 3024, 2, 523, 37, 1911, 3, 12, 2993, 7961, 151, 7962]\n",
      "origin string is:Hello tensorflow! one day I will keep you safe, keep you sound. I promise you!\n"
     ]
    }
   ],
   "source": [
    "sample_string=\"Hello tensorflow! one day I will keep you safe, keep you sound. I promise you!\"\n",
    "encode_string=encoder.encode(sample_string)\n",
    "print(f'Encode string is: {encode_string}')\n",
    "origin_string=encoder.decode(encode_string)\n",
    "print(f'origin string is:{origin_string}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "origin_string == sample_string"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4025 ---> Hell\n",
      "222 ---> o \n",
      "943 ---> ten\n",
      "2327 ---> sor\n",
      "2934 ---> flow\n",
      "90 ---> ! \n",
      "45 ---> one \n",
      "414 ---> day \n",
      "12 ---> I \n",
      "96 ---> will \n",
      "523 ---> keep \n",
      "37 ---> you \n",
      "3024 ---> safe\n",
      "2 ---> , \n",
      "523 ---> keep \n",
      "37 ---> you \n",
      "1911 ---> sound\n",
      "3 ---> . \n",
      "12 ---> I \n",
      "2993 ---> promise\n",
      "7961 --->  \n",
      "151 ---> you\n",
      "7962 ---> !\n"
     ]
    }
   ],
   "source": [
    "for index in encode_string:\n",
    "    print(f'{index} ---> {encoder.decode([index])}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "尝试获取所有词汇，但是因为输入的评论不规整。\n",
    "所得的词汇表不是很准"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['A', 'female', 'vampire', 'kills', 'young', 'women', 'and', 'paints', 'with', 'their', 'blood.', 'She', 'has', 'an', 'assistant', 'who', \"doesn't\", 'want', 'to', 'be', 'a', 'vampire,', 'so', 'he', 'has', 'to', 'do', 'what', 'she', 'orders', 'or', 'be', 'turned', 'into', 'a', 'blood', 'sucker.', 'After', 'a', 'few', 'kills,', 'the', 'assistant', 'gets', 'remorse', 'and', 'falls', 'in', 'love', 'with', 'a', 'homeless', 'girl.<br', '/><br', '/>What', 'can', 'I', 'say', 'about', 'this', 'movie', '?', 'That', 'its', 'pacing', 'is', 'over-slow,', 'that', 'it', 'has', 'some', 'strange', 'sound', 'effects', '(never', 'a', 'bite', 'sounded', 'so', 'strange)', 'and', 'ambiance', '(new', 'jazz', 'here', 'I', 'come)', 'and', 'that', 'lights', \"don't\", 'seem', 'to', 'be', 'included', 'on', 'the', 'set.', 'It', 'looks', 'like', 'an', '\"auteur\"', 'horror', 'movie', 'with', 'all', 'the', 'self-sufficiency', 'inside.<br', '/><br', '/>The', 'plot', 'is', 'completely', 'stupid', 'and', 'as', 'you', 'can', 'guess,', \"it's\", 'the', 'female', 'vampire', 'who', 'explains', 'how', 'to', 'kill', 'her', 'even', 'if', 'she', \"doesn't\", 'have', 'to', 'do', 'it;', 'of', 'course,', 'crosses,', 'light,', 'garlic', 'and', 'sticks', \"don't\", 'work.<br', '/><br', \"/>It's\", 'not', 'even', 'a', 'funny', 'lousy', 'movie.', 'Perhaps', 'with', 'some', 'friends', 'and', 'a', 'lot', 'of', 'beers,', 'it', \"can't\", 'have', 'its', 'funny', 'sides', '(to', 'be', 'honest,', \"it's\", 'funny', 'during', '10', '-', '15', 'minutes', 'near', 'the', 'end', 'of', 'the', 'movie).', \"Don't\", 'be', 'fooled', 'by', 'the', 'Troma', 'sticker,', \"it's\", 'one', 'the', 'bad', 'movie', 'they', 'present.']\n",
      "['<br', '/><br', '/>I', 'take', 'issue', 'with', 'the', 'other', \"reviewer's\", 'comments', 'for', 'the', 'simple', 'reason', 'that', 'this', 'is', 'a', 'MYSTERY', 'FILM,', 'not', 'a', 'supernatural', 'one!', 'It', 'is', 'not', 'the', 'only', 'film', 'to', 'have', 'a', 'seemingly', '\"supernatural\"', 'explanation', '(\"vampires\"),', 'but', 'turns', 'out', 'to', 'be', 'a', 'very', 'mundance', 'one.<br', '/><br', '/>Other', 'films', 'that', 'come', 'to', 'mind', 'are', 'Edgar', \"Wallace's\", '\"Before', 'Dawn\"', 'and', 'the', '(more', 'famous)', '\"Mark', 'of', 'the', 'Vampire\".', '<br', '/><br', '/>The', 'film', 'does', 'a', 'WONDERFUL', 'job', 'in', 'creating', 'a', 'very', '\"spooky', 'atmosphere\",', 'similar', 'DRACULA,', 'when', 'Renfield', 'meets', 'the', 'Count', 'on', 'the', 'staircase', 'of', 'his', 'castle,', 'or', 'in', 'MARK', 'OF', 'THE', 'VAMPIRE,', 'when', 'the', 'two', 'people', 'look', 'thru', 'the', 'windows', 'of', 'the', 'castle', 'ruins', 'and', 'see', 'a', '\"corpse\"', 'playing', 'an', 'organ,', 'while', 'Luna', 'descends', 'using', 'wings!', 'VERY', 'surreal!<br', '/><br', '/>If', 'one', 'likes', 'these', '(often', 'silent)', 'atmospheric', 'touches,', 'THIS', 'film', 'is', 'a', 'MUST!<br', '/><br', '/>Norm', 'Vogel']\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(280617, 25000)"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "vocabulary_set=set()\n",
    "count=0\n",
    "# sentence是一个truple，0是语句的tensor，1是label的tensor\n",
    "for sentence in dataset['train']:\n",
    "    count+=1\n",
    "    words=encoder.decode(sentence[0].numpy()).split()\n",
    "    if count%10000==0:\n",
    "        print(words)\n",
    "    vocabulary_set.update(words)\n",
    "len(vocabulary_set),count"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 准备训练集"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "BUFFER_SIZE=10000\n",
    "BATCH_SIZE=64"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(TensorShape([None]), TensorShape([]))"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_dataset.output_shapes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "padded_shapes=(\n",
    "#         tf.TensorShape([6]),\n",
    "#         tf.TensorShape([])\n",
    "    [None,],[]\n",
    "        )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# train_dataset=train_dataset.shuffle(BUFFER_SIZE)\n",
    "# train_dataset=train_dataset.padded_batch(BATCH_SIZE,padded_shapes=train_dataset.output_shapes)\n",
    "# test_dataset = test_dataset.padded_batch(BATCH_SIZE, test_dataset.output_shapes)\n",
    "\n",
    "# 这样写更好\n",
    "train_dataset=train_dataset.shuffle(BUFFER_SIZE)\n",
    "train_dataset=train_dataset.padded_batch(BATCH_SIZE,padded_shapes=([-1,],[]))\n",
    "test_dataset = test_dataset.padded_batch(BATCH_SIZE, padded_shapes=padded_shapes)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 创建模型"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "embedding (Embedding)        (None, None, 64)          523840    \n",
      "_________________________________________________________________\n",
      "bidirectional (Bidirectional (None, 128)               66048     \n",
      "_________________________________________________________________\n",
      "dense (Dense)                (None, 64)                8256      \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 1)                 65        \n",
      "=================================================================\n",
      "Total params: 598,209\n",
      "Trainable params: 598,209\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model=tf.keras.Sequential([\n",
    "    tf.keras.layers.Embedding(encoder.vocab_size,64),\n",
    "    tf.keras.layers.Bidirectional(tf.keras.layers.LSTM(64)),\n",
    "    tf.keras.layers.Dense(64,activation='relu'),\n",
    "    tf.keras.layers.Dense(1,activation='sigmoid')\n",
    "])\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.compile(optimizer='adam',\n",
    "             loss='binary_crossentropy',\n",
    "             metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-------------load the model-----------------\n"
     ]
    }
   ],
   "source": [
    "checkpoint_save_path = \"./checkpoint/imdb_LSTM.ckpt\"\n",
    "\n",
    "if os.path.exists(checkpoint_save_path + '.index'):\n",
    "    print('-------------load the model-----------------')\n",
    "    model.load_weights(checkpoint_save_path)\n",
    "\n",
    "cp_callback = tf.keras.callbacks.ModelCheckpoint(filepath=checkpoint_save_path,\n",
    "                                                 save_weights_only=True,\n",
    "                                                 # monitor='loss',\n",
    "                                                 # save_best_only=True,\n",
    "                                                 verbose=2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "本地训练太慢，已经在colab中训练完毕，上方已经加载完成，不需要再训练了"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "histrory=model.fit(train_dataset,epochs=10,validation_data=test_dataset,callbacks=[cp_callback])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "391/391 [==============================] - 530s 1s/step - loss: 0.7831 - accuracy: 0.8578\n",
      "Test loss:0.783114426657367, Test accuracy:0.8577600121498108\n"
     ]
    }
   ],
   "source": [
    "test_loss,test_accuracy=model.evaluate(test_dataset)\n",
    "print(\"Test loss:{}, Test accuracy:{}\".format(test_loss,test_accuracy))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "下面对我们自己的评论进行预测  \n",
    "因为我们的训练集都进行了pad，如果我们自己的评论没有进行pad，在预测时会有较大的影响"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "def pad_to_size(vec,size):\n",
    "    zeros=[0]*(size-len(vec))\n",
    "    vec.extend(zeros)\n",
    "    return vec"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "def sample_predict(sentence,ispad):\n",
    "    encoded_sample_pred_text=encoder.encode(sentence)\n",
    "    if ispad:\n",
    "        encoded_sample_pred_text=pad_to_size(encoded_sample_pred_text,64)\n",
    "    encoded_sample_pred_text=tf.cast(encoded_sample_pred_text,tf.float32)\n",
    "    predictions=model.predict(tf.expand_dims(encoded_sample_pred_text,0))\n",
    "    return predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "comment is: this movie is bad. but the actor is very handsome and I like him. but I will not recommend this movie.\n",
      "here is the point:\n",
      "padding result is : [[0.17458665]]\n",
      "no padding result is : [[0.22444972]]\n",
      "******\n",
      "comment is: The movie was cool. The animation and the graphics were out of this world. I would recommend this movie.\n",
      "here is the point:\n",
      "padding result is : [[0.9981263]]\n",
      "no padding result is : [[0.99877375]]\n",
      "******\n",
      "comment is: actually, I am the actor's fans. But his performance in the movie break my heart.\n",
      "here is the point:\n",
      "padding result is : [[0.47038242]]\n",
      "no padding result is : [[0.7395189]]\n",
      "******\n",
      "comment is: The characters is not famous, but their performances make the movie reach a very high level! \n",
      "here is the point:\n",
      "padding result is : [[0.9868593]]\n",
      "no padding result is : [[0.9783811]]\n",
      "******\n",
      "comment is: The movie is very ironic.This film criticizes the social phenomena without conscience\n",
      "here is the point:\n",
      "padding result is : [[0.99971634]]\n",
      "no padding result is : [[0.9996995]]\n",
      "******\n"
     ]
    }
   ],
   "source": [
    "sample_pred_texts =['this movie is bad. but the actor is very handsome and I like him. but I will not recommend this movie.',\n",
    "                   'The movie was cool. The animation and the graphics were out of this world. I would recommend this movie.',\n",
    "                    \"actually, I am the actor's fans. But his performance in the movie break my heart.\",\n",
    "                    'The characters is not famous, but their performances make the movie reach a very high level! ',\n",
    "                    'The movie is very ironic.This film criticizes the social phenomena without conscience'\n",
    "                    ]\n",
    "for sample_pred_text in sample_pred_texts:\n",
    "    prediction_without_padding=sample_predict(sample_pred_text,ispad=False)\n",
    "    prediction_with_padding=sample_predict(sample_pred_text,ispad=True)\n",
    "    print('comment is:',sample_pred_text)\n",
    "    print('here is the point:')\n",
    "    print('padding result is :',prediction_with_padding)\n",
    "    print('no padding result is :',prediction_without_padding)\n",
    "    print('******')\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
